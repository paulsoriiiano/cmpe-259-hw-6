{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPu9OpTt3VSBJrsuteS2g1D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/paulsoriiiano/cmpe-259-hw-6/blob/main/Homework6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Homework 6: Retrieval Augmented Generation\n",
        "**Objective**: Build a smart RAG system that can read PDFs with tables and answer questions using LangChain and Ollama. Your goal is to create a pipeline that finds useful information and gives clear, accurate answers."
      ],
      "metadata": {
        "id": "FDWPWPyQO6DG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Project Set-Up"
      ],
      "metadata": {
        "id": "bbtJ2D-5Qd5y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "%%bash\n",
        "\n",
        "pip install -qU faiss faiss-cpu                                                         # Vector database\n",
        "pip install -qU gradio                                                                  # UI\n",
        "pip install -qU langchain langchain-community langchain-core langchain-huggingface      # LLM-based agents\n",
        "pip install -qU PyMuPDF                                                                 # reading PDFs"
      ],
      "metadata": {
        "id": "GRET6mLMQf1P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1. Document Ingesting and Chunking\n",
        "* Load at least one .pdf document containing tables (e.g., financial report, scientific\n",
        "article).\n",
        "* Extract both text and tables from the document. You may use tools like PyMuPDF,\n",
        "pdfplumber, or pdf2image + OCR or AI based tools like Unstructured.io\n",
        "* Apply custom chunking strategies:\n",
        "  * Use RecursiveCharacterTextSplitter.\n",
        "  * Ensure table content is chunked logically and not broken across chunks.\n",
        "  * *HP: add metadata such as table number, section title, or page number.*"
      ],
      "metadata": {
        "id": "QM8V2TdtPJun"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2. Vector Store Indexing\n",
        "* Store the processed chunks into a vector database (Chroma or FAISS).\n",
        "* *HP: Implement metadata-based filtering (e.g., search within a specific section or document type).*"
      ],
      "metadata": {
        "id": "j13yG2qAPNJe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3. LLM Integration and Retrieval\n",
        "* Connect a local LLM (via Ollama or another LangChain-supported endpoint).\n",
        "* Set up a `RetrievalQA` or `ConversationalRetrievalChain` using LangChain.\n",
        "* Pass user queries and retrieved chunks to the LLM to generate responses.\n",
        "* Ensure the LLM can:\n",
        "  * Extract specific facts (e.g., \"What is the total revenue for 2022?\")\n",
        "  * Answer contextual questions"
      ],
      "metadata": {
        "id": "jvu0EemGPQDw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 4. Evaluation & Use Case Demonstration\n",
        "* Test the pipeline with three different types of queries, including at least one involving\n",
        "table-based information (e.g., \"What is the total revenue in 2022?\").\n",
        "\n",
        "* Compare the answers to the document’s actual content."
      ],
      "metadata": {
        "id": "MOyp91FgPa2c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [HP] Part 5. UI Component\n",
        "Add a UI component (e.g., Streamlit or Gradio) where users can upload a PDF, type a query, and get answers"
      ],
      "metadata": {
        "id": "vqwhgfAePfZX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 6. Reflection\n",
        "Write a short reflection (200–300 words) describing:\n",
        "* Challenges faced during table extraction.\n",
        "* Accuracy of responses.\n",
        "* What you would improve with more time."
      ],
      "metadata": {
        "id": "ceh-HXSsPmMd"
      }
    }
  ]
}